{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf13cc91-7305-426c-ad15-2252f543b8d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# One Jupyter notebook. From GeoJSON to .xml "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a8a0247-2ce7-4436-b874-2edfa336c4b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac38f724-596e-48f2-ae0c-29bb8e71030b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas\n",
    "import numpy\n",
    "import datetime\n",
    "datetime = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "import tifffile\n",
    "import shapely\n",
    "# import streamlit as st\n",
    "from python_functions import dataframe_to_xml_v2\n",
    "from lmd.lib import SegmentationLoader\n",
    "from lmd.lib import Collection, Shape\n",
    "from lmd import tools\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36985444-7a8a-4bf8-9da8-57c786abcfdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## From GeoJSON to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef43c7fe-4e7f-4595-9d99-7aa268099a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#user defined variables:\n",
    "path_to_file = '/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD/example_input/test_input.geojson'\n",
    "path_to_save_files = '/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD/example_output/'\n",
    "#the naming of these should match exactly the names in the geoJSON file\n",
    "calibration_points = ['calib12','calib13','calib20']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "533bc771-e333-41fd-9f62-fb2665ba0f46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Samples and wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a30eb9-2d04-454c-b496-59f8b843cce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you want to pass a custom well loadout use the following dictionary:  \n",
    "# The dictionary keys will have to be the class name used in qupath, it has to be the exact names.  \n",
    "# please choose wells with a 2-row 2-column margin. not rows (A, B, N, O) not columns (1,2,23,24)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f36ed5-42b7-478c-9d77-3cc9cbda0edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_and_wells = { \n",
    " '187_HBC_mid_3': 'C3',\n",
    " '187_HBC_nVEC_1': 'C4',\n",
    " '187_HBC_nVEC_2': 'C5',\n",
    " '187_HBC_mid_2': 'C6',\n",
    " '187_HBC_nTroph_3': 'C7',\n",
    " '187_HBC_nTroph_1': 'C8',\n",
    " '187_HBC_mid_1': 'C9',\n",
    " '187_HBC_nVEC_3': 'C10',\n",
    " '187_HBC_nTroph_2': 'C11',\n",
    " '108_STB_nVEC_1': 'F3',\n",
    " '108_STB_nVEC_2': 'F4',\n",
    " '108_STB_nVEC_3': 'F5',\n",
    " '108_STB_gen_1': 'F6',\n",
    " '108_STB_gen_2': 'F7',\n",
    " '108_STB_gen_3': 'F8',\n",
    " '108_CTB_1_1': 'F9',\n",
    " '108_CTB_2_1': 'F10',\n",
    " '108_CTB_3_1': 'F11',\n",
    " '108_HBC_nTroph_1': 'G3',\n",
    " '108_HBC_nTroph_2': 'G4',\n",
    " '108_HBC_nTroph_3': 'G5',\n",
    " '108_HBC_nVEC_1': 'G6',\n",
    " '108_HBC_nVEC_2': 'G7',\n",
    " '108_HBC_nVEC_3': 'G8',\n",
    " '108_HBC_mid_1': 'G9',\n",
    " '108_HBC_mid_2': 'G10',\n",
    " '108_HBC_mid_3': 'G11',\n",
    " '108_CCT_1': 'H3',\n",
    " '108_CCT_2': 'H4',\n",
    " '108_CCT_3': 'H5',\n",
    " '108_VEC_1': 'H6',\n",
    " '108_VEC_2': 'H7',\n",
    " '108_VEC_3': 'H8',\n",
    " '108_Str_1': 'H9',\n",
    " '108_Str_2': 'H10',\n",
    " '108_Str_3': 'H11',\n",
    " '187_STB_nVEC_1': 'D3',\n",
    " '187_STB_nVEC_2': 'D4',\n",
    " '187_STB_nVEC_3': 'D5',\n",
    " '187_STB_gen_1': 'D6',\n",
    " '187_STB_gen_2': 'D7',\n",
    " '187_STB_gen_3': 'D8',\n",
    " '187_CTB_1': 'D9',\n",
    " '187_CTB_2': 'D10',\n",
    " '187_CTB_3': 'D11',\n",
    " '187_CCT_1': 'E3',\n",
    " '187_CCT_2': 'E4',\n",
    " '187_CCT_3': 'E5',\n",
    " '187_VEC_1': 'E6',\n",
    " '187_VEC_2': 'E7',\n",
    " '187_VEC_3': 'E8',\n",
    " '187_str_1': 'E9',\n",
    " '187_str_2': 'E10',\n",
    " '187_str_3': 'E11'\n",
    " }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0cc0a7b-dcd3-4cb5-b30f-42414f3576d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0dfb0dd-c054-4594-a4de-f645f82464d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### process dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_QC_geojson_file(geojson_path: str, list_of_calibpoint_names: list = ['calib1','calib2','calib3']):\n",
    "\n",
    "   #load geojson file\n",
    "   df = geopandas.read_file(geojson_path)\n",
    "\n",
    "   #save calib points in a list\n",
    "   caliblist = []\n",
    "   for point_name in list_of_calibpoint_names:\n",
    "      if point_name in df['name'].unique():\n",
    "            caliblist.append(df.loc[df['name'] == point_name, 'geometry'].values[0])\n",
    "      # else:\n",
    "      #       st.write('Your given name is not present in the file', \n",
    "      #       f'These are the calib points you passed: {list_of_calibpoint_names}',\n",
    "      #       f\"These are the calib points found in the geojson you gave me: {df['name'].unique()}\")\n",
    "   #create coordenate list\n",
    "   listarray = []\n",
    "   for point in caliblist:\n",
    "      listarray.append([point.x, point.y])\n",
    "   calib_np_array = numpy.array(listarray)\n",
    "\n",
    "   #now that calibration points are saved, remove them from the dataframe\n",
    "   df = df[df['name'].isin(list_of_calibpoint_names) == False]\n",
    "\n",
    "   #check and remove empty classifications \n",
    "   if df['classification'].isna().sum() !=0 :\n",
    "      # st.write(f\"you have {df['classification'].isna().sum()} NaNs in your classification column\",\n",
    "      #       \"these are unclassified objects from Qupath, they will be ignored\") \n",
    "      df = df[df['classification'].notna()]\n",
    "\n",
    "   #check for MultiPolygon objects\n",
    "   if 'MultiPolygon' in df.geometry.geom_type.value_counts().keys():\n",
    "      # st.write('MultiPolygon objects present:',\n",
    "      # #print out the classification name of the MultiPolygon objects\n",
    "      # f\"{df[df.geometry.geom_type == 'MultiPolygon']['classification']}\", \n",
    "      # 'these are not supported, please convert them to polygons in Qupath',\n",
    "      # 'the script will continue but these objects will be ignored')\n",
    "      #remove MultiPolygon objects\n",
    "      df = df[df.geometry.geom_type != 'MultiPolygon']\n",
    "\n",
    "   # reformat shape coordenate list\n",
    "   df['coords'] = numpy.nan\n",
    "   df['coords'] = df['coords'].astype('object')\n",
    "   # simplify to reduce number of points\n",
    "   df['simple'] = df.geometry.simplify(1)\n",
    "   for i in df.index:\n",
    "      geom=df.at[i, 'simple']\n",
    "      tmp = list(geom.exterior.coords)\n",
    "      tmp_lol = [list(i) for i in tmp]\n",
    "      df.at[i,'coords'] = tmp_lol\n",
    "\n",
    "   #extract classification name into a new column\n",
    "   df['Name'] = numpy.nan\n",
    "   for i in df.index:\n",
    "      tmp = df.classification[i].get('name')\n",
    "      df.at[i,'Name'] = tmp\n",
    "\n",
    "   # st.write('The file loading is complete')\n",
    "\n",
    "   #save dataframe as csv\n",
    "   df.to_csv(f\"./{datetime}_QCed_geojson.csv\", index=False)\n",
    "   #save numpy array as csv\n",
    "   numpy.savetxt(f\"./{datetime}_calib_points.csv\", calib_np_array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2432633645.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 34\u001b[0;36m\u001b[0m\n\u001b[0;31m    # st.write('The samples and wells scheme QC is done!')\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def load_and_QC_SamplesandWells(samples_and_wells_input, df_csv):\n",
    "\n",
    "   df = pandas.read_csv(df_csv)\n",
    "\n",
    "   # parse common human copy paste formats\n",
    "   # remove newlines\n",
    "   samples_and_wells_processed = samples_and_wells_input.replace(\"\\n\", \"\")\n",
    "   # remove spaces\n",
    "   samples_and_wells_processed = samples_and_wells_processed.replace(\" \", \"\")\n",
    "   #parse into python dictionary\n",
    "   samples_and_wells = ast.literal_eval(samples_and_wells_processed)\n",
    "\n",
    "   #create list of acceptable wells, default is using a space in between columns\n",
    "   list_of_acceptable_wells =[]\n",
    "   for row in list(string.ascii_uppercase[2:14]):\n",
    "      for column in range(2,22):\n",
    "         list_of_acceptable_wells.append(str(row) + str(column))\n",
    "\n",
    "   #check for improper wells\n",
    "   # for well in samples_and_wells.values():\n",
    "   #    if well not in list_of_acceptable_wells:\n",
    "            # st.write(f'Your well {well} is not in the list of acceptable wells, please correct it',\n",
    "            # 'the LMD is not able to collect into this well, the script will stop here')\n",
    "            # st.stop()\n",
    "\n",
    "   #check that names in df are all present in the samples and wells\n",
    "   # for name in df.Name.unique():\n",
    "      # if name not in samples_and_wells.keys():\n",
    "            # st.write(f'Your name {name} is not in the list of samples_and_wells, please correct either',\n",
    "            # 'please change the class name in Qupath or add it to the samples_and_wells dictionary',\n",
    "            # 'and then rerun the web app')\n",
    "            # st.stop()\n",
    "\n",
    "   # st.write('The samples and wells scheme QC is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_point_1 = \"calib12\"\n",
    "calibration_point_2 = \"calib13\"\n",
    "calibration_point_3 = \"calib20\"\n",
    "list_of_calibpoint_names = [calibration_point_1, calibration_point_2, calibration_point_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2100124983.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    samples_and_wells_input = \"{\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "samples_and_wells_input = \"{ \n",
    " '187_HBC_mid_3': 'C3',\n",
    " '187_HBC_nVEC_1': 'C4',\n",
    " '187_HBC_nVEC_2': 'C5',\n",
    " '187_HBC_mid_2': 'C6',\n",
    " '187_HBC_nTroph_3': 'C7',\n",
    " '187_HBC_nTroph_1': 'C8',\n",
    " '187_HBC_mid_1': 'C9',\n",
    " '187_HBC_nVEC_3': 'C10',\n",
    " '187_HBC_nTroph_2': 'C11',\n",
    " '108_STB_nVEC_1': 'F3',\n",
    " '108_STB_nVEC_2': 'F4',\n",
    " '108_STB_nVEC_3': 'F5',\n",
    " '108_STB_gen_1': 'F6',\n",
    " '108_STB_gen_2': 'F7',\n",
    " '108_STB_gen_3': 'F8',\n",
    " '108_CTB_1_1': 'F9',\n",
    " '108_CTB_2_1': 'F10',\n",
    " '108_CTB_3_1': 'F11',\n",
    " '108_HBC_nTroph_1': 'G3',\n",
    " '108_HBC_nTroph_2': 'G4',\n",
    " '108_HBC_nTroph_3': 'G5',\n",
    " '108_HBC_nVEC_1': 'G6',\n",
    " '108_HBC_nVEC_2': 'G7',\n",
    " '108_HBC_nVEC_3': 'G8',\n",
    " '108_HBC_mid_1': 'G9',\n",
    " '108_HBC_mid_2': 'G10',\n",
    " '108_HBC_mid_3': 'G11',\n",
    " '108_CCT_1': 'H3',\n",
    " '108_CCT_2': 'H4',\n",
    " '108_CCT_3': 'H5',\n",
    " '108_VEC_1': 'H6',\n",
    " '108_VEC_2': 'H7',\n",
    " '108_VEC_3': 'H8',\n",
    " '108_Str_1': 'H9',\n",
    " '108_Str_2': 'H10',\n",
    " '108_Str_3': 'H11',\n",
    " '187_STB_nVEC_1': 'D3',\n",
    " '187_STB_nVEC_2': 'D4',\n",
    " '187_STB_nVEC_3': 'D5',\n",
    " '187_STB_gen_1': 'D6',\n",
    " '187_STB_gen_2': 'D7',\n",
    " '187_STB_gen_3': 'D8',\n",
    " '187_CTB_1': 'D9',\n",
    " '187_CTB_2': 'D10',\n",
    " '187_CTB_3': 'D11',\n",
    " '187_CCT_1': 'E3',\n",
    " '187_CCT_2': 'E4',\n",
    " '187_CCT_3': 'E5',\n",
    " '187_VEC_1': 'E6',\n",
    " '187_VEC_2': 'E7',\n",
    " '187_VEC_3': 'E8',\n",
    " '187_str_1': 'E9',\n",
    " '187_str_2': 'E10',\n",
    " '187_str_3': 'E11' }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection(df_csv, calib_np_array_csv, samples_and_wells_input ):\n",
    "    df = pandas.read_csv(df_csv)\n",
    "    calib_np_array = numpy.loadtxt(calib_np_array_csv, delimiter=\",\")\n",
    "\n",
    "    # samples_and_wells_processed = samples_and_wells_input.replace(\"\\n\", \"\")\n",
    "    # samples_and_wells_processed = samples_and_wells_processed.replace(\" \", \"\")\n",
    "    # samples_and_wells = ast.literal_eval(samples_and_wells_processed)\n",
    "    samples_and_wells = samples_and_wells_input\n",
    "\n",
    "    #create the collection of py-lmd-env package\n",
    "    #uses caliblist passed on the function, order matters\n",
    "    #orientation vector is for QuPath coordenate system\n",
    "    the_collection = Collection(calibration_points = calib_np_array)\n",
    "    the_collection.orientation_transform = numpy.array([[1,0 ], [0,-1]])\n",
    "    for i in df.index:\n",
    "        the_collection.new_shape(df.at[i,'coords'], well = samples_and_wells[df.at[i, \"Name\"]])\n",
    "\n",
    "    the_collection.plot(save_name= \"./TheCollection.png\")\n",
    "    # st.image(\"./TheCollection.png\", caption='Your Contours', use_column_width=True)\n",
    "    # st.write(the_collection.stats())\n",
    "    the_collection.save(f\"./{datetime}_LMD_ready_contours.xml\")\n",
    "\n",
    "\n",
    "    #create and export dataframe with sample placement in 384 well plate\n",
    "    rows_A_P= [i for i in string.ascii_uppercase[:16]]\n",
    "    columns_1_24 = [str(i) for i in range(1,25)]\n",
    "    df_wp384 = pd.DataFrame('',columns=columns_1_24, index=rows_A_P)\n",
    "    #fill in the dataframe with samples and wells\n",
    "    for i in samples_and_wells:\n",
    "        location = samples_and_wells[i]\n",
    "        df_wp384.at[location[0],location[1:]] = i\n",
    "    #save dataframe as csv\n",
    "    df_wp384.to_csv(f\"./{datetime}_384_wellplate.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/grkjlk8s223dy6234rnz1885mxz2_6/T/ipykernel_16963/3341259843.py:55: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '187_HBC_mid_1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i,'Name'] = tmp\n"
     ]
    }
   ],
   "source": [
    "load_and_QC_geojson_file(geojson_path='/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/example_input/test_input.geojson', list_of_calibpoint_names=list_of_calibpoint_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_np_array = numpy.loadtxt(f\"./{datetime}_calib_points.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calib_np_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(f\"./{datetime}_QCed_geojson.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.at[0,'coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x\u001b[39m.\u001b[39;49mdtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "please provide a numpy array of shape (N, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m create_collection(df_csv\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m{\u001b[39;49;00mdatetime\u001b[39m}\u001b[39;49;00m\u001b[39m_QCed_geojson.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, calib_np_array_csv\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m{\u001b[39;49;00mdatetime\u001b[39m}\u001b[39;49;00m\u001b[39m_calib_points.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, samples_and_wells_input\u001b[39m=\u001b[39;49msamples_and_wells)\n",
      "\u001b[1;32m/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m the_collection\u001b[39m.\u001b[39morientation_transform \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m ], [\u001b[39m0\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mindex:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     the_collection\u001b[39m.\u001b[39;49mnew_shape(df\u001b[39m.\u001b[39;49mat[i,\u001b[39m'\u001b[39;49m\u001b[39mcoords\u001b[39;49m\u001b[39m'\u001b[39;49m], well \u001b[39m=\u001b[39;49m samples_and_wells[df\u001b[39m.\u001b[39;49mat[i, \u001b[39m\"\u001b[39;49m\u001b[39mName\u001b[39;49m\u001b[39m\"\u001b[39;49m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m the_collection\u001b[39m.\u001b[39mplot(save_name\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./TheCollection.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# st.image(\"./TheCollection.png\", caption='Your Contours', use_column_width=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jnimoca/Jose_BI/Repositories/Qupath_to_LMD_v2/QuPath_to_LMD.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# st.write(the_collection.stats())\u001b[39;00m\n",
      "File \u001b[0;32m~/Jose_BI/Repositories/py-lmd/src/lmd/lib.py:211\u001b[0m, in \u001b[0;36mCollection.new_shape\u001b[0;34m(self, points, well, name)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_shape\u001b[39m(\u001b[39mself\u001b[39m, points: np\u001b[39m.\u001b[39mndarray, \n\u001b[1;32m    198\u001b[0m              well: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[1;32m    199\u001b[0m              name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    201\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Directly create a new Shape in the current collection.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m        name: Name of the shape.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     to_add \u001b[39m=\u001b[39m Shape(points, well\u001b[39m=\u001b[39;49mwell, name\u001b[39m=\u001b[39;49mname, orientation_transform \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morientation_transform)\n\u001b[1;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_shape(to_add)\n",
      "File \u001b[0;32m~/Jose_BI/Repositories/py-lmd/src/lmd/lib.py:385\u001b[0m, in \u001b[0;36mShape.__init__\u001b[0;34m(self, points, well, name, orientation_transform)\u001b[0m\n\u001b[1;32m    381\u001b[0m point_shapes \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39mshape\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(point_shapes) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m \n\u001b[1;32m    383\u001b[0m     (point_shapes[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     (point_shapes[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)):\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mplease provide a numpy array of shape (N, 2)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoints: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m points\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m name\n",
      "\u001b[0;31mValueError\u001b[0m: please provide a numpy array of shape (N, 2)"
     ]
    }
   ],
   "source": [
    "create_collection(df_csv=f\"./{datetime}_QCed_geojson.csv\", calib_np_array_csv=f\"./{datetime}_calib_points.csv\", samples_and_wells_input=samples_and_wells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39a634b4-5386-452f-86e7-1a1af6ebafc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing from GeoJSON to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 load and QC geojson file\n",
    "def load_and_QC_geojson_file(geojson_path: str, list_of_calibpoint_names: list = ['calib1','calib2','calib3']):\n",
    "\n",
    "    #load geojson file\n",
    "    df = geopandas.read_file(path_to_file)\n",
    "\n",
    "    #save calib points in a list\n",
    "    caliblist = []\n",
    "    for point_name in list_of_calibpoint_names:\n",
    "        if point_name in df['name'].unique():\n",
    "            caliblist.append(df.loc[df['name'] == point_name, 'geometry'].values[0])\n",
    "        else:\n",
    "            st.write('Your given name is not present in the file', \n",
    "            f'These are the calib points you passed: {list_of_calibpoint_names}',\n",
    "            f\"These are the calib points found in the geojson you gave me: {df['name'].unique()}\")\n",
    "    #create coordenate list\n",
    "    listarray = []\n",
    "    for point in pointlist:\n",
    "        listarray.append([point.x, point.y])\n",
    "    calib_np_array = np.array(listarray)\n",
    "\n",
    "    #now that calibration points are saved, remove them from the dataframe\n",
    "    df = df[df['name'].isin(list_of_calibpoint_names) == False]\n",
    "\n",
    "    #check and remove empty classifications \n",
    "    if df['classification'].isna().sum() !=0 :\n",
    "        st.write(f\"you have {df['classification'].isna().sum()} NaNs in your classification column\",\n",
    "                \"these are unclassified objects from Qupath, they will be ignored\") \n",
    "        df = df[df['classification'].notna()]\n",
    "\n",
    "    #check for MultiPolygon objects\n",
    "    if 'MultiPolygon' in df.geometry.geom_type.value_counts().keys():\n",
    "        st.write('MultiPolygon objects present:',\n",
    "        #print out the classification name of the MultiPolygon objects\n",
    "        f\"{df[df.geometry.geom_type == 'MultiPolygon']['classification']}\", \n",
    "        'these are not supported, please convert them to polygons in Qupath',\n",
    "        'the script will continue but these objects will be ignored')\n",
    "        #remove MultiPolygon objects\n",
    "        df = df[df.geometry.geom_type != 'MultiPolygon']\n",
    "\n",
    "    # reformat shape coordenate list\n",
    "    df['coords'] = np.nan\n",
    "    df['coords'] = df['coords'].astype('object')\n",
    "    # simplify to reduce number of points\n",
    "    df['simple'] = df.geometry.simplify(1)\n",
    "    for i in df.index:\n",
    "        geom=df.at[i, 'simple']\n",
    "        tmp = list(geom.exterior.coords)\n",
    "        tmp_lol = [list(i) for i in tmp]\n",
    "        df.at[i,'coords'] = tmp_lol\n",
    "\n",
    "    #extract classification name into a new column\n",
    "    df['Name'] = np.nan\n",
    "    for i in df.index:\n",
    "        tmp = df.classification[i].get('name')\n",
    "        df.at[i,'Name'] = tmp\n",
    "\n",
    "    st.write('The file loading is complete')\n",
    "\n",
    "    return(df,calib_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 parse and check samples and wells\n",
    "def load_and_QC_SamplesandWells(samples_and_wells_input, df):\n",
    "\n",
    "    # parse common human copy paste formats\n",
    "    # remove newlines\n",
    "    samples_and_wells_processed = samples_and_wells_input.replace(\"\\n\", \"\")\n",
    "    # remove spaces\n",
    "    samples_and_wells_processed = samples_and_wells_processed.replace(\" \", \"\")\n",
    "    #parse into python dictionary\n",
    "    samples_and_wells = ast.literal_eval(samples_and_wells_processed)\n",
    "\n",
    "    #create list of acceptable wells, default is using a space in between columns\n",
    "    list_of_acceptable_wells =[]\n",
    "    for row in list(string.ascii_uppercase[2:14]):\n",
    "        for column in range(2,22):\n",
    "            list_of_acceptable_wells.append(str(row) + str(column))\n",
    "\n",
    "    #check for improper wells\n",
    "    for well in samples_and_wells.values():\n",
    "        if well not in list_of_acceptable_wells:\n",
    "            st.write(f'Your well {well} is not in the list of acceptable wells, please correct it',\n",
    "            'the LMD is not able to collect into this well, the script will stop here')\n",
    "            st.stop()\n",
    "\n",
    "    #check that names in df are all present in the samples and wells\n",
    "    for name in df.Name.unique():\n",
    "        if name not in samples_and_wells.keys():\n",
    "            st.write(f'Your name {name} is not in the list of samples_and_wells, please correct either',\n",
    "            'please change the class name in Qupath or add it to the samples_and_wells dictionary',\n",
    "            'and then rerun the web app')\n",
    "            st.stop()\n",
    "    \n",
    "    return samples_and_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 create collection\n",
    "def create_collection(df = df, calib_np_array = calib_np_array, samples_and_wells = samples_and_wells ):\n",
    "    #create the collection of py-lmd-env package\n",
    "    #uses caliblist passed on the function, order matters\n",
    "    #orientation vector is for QuPath coordenate system\n",
    "    the_collection = Collection(calibration_points = calib_np_array)\n",
    "    the_collection.orientation_transform = np.array([[1,0 ], [0,-1]])\n",
    "    for i in df.index:\n",
    "        the_collection.new_shape(df.at[i,'coords'], well = samples_and_wells[df.at[i, \"Name\"]])\n",
    "\n",
    "    the_collection.plot(save_name= \"./TheCollection.png\")\n",
    "    st.image(\"./TheCollection.png\", caption='Your Contours', use_column_width=True)\n",
    "    st.write(the_collection.stats())\n",
    "    \n",
    "    the_collection.save(f\"./{datetime}_LMD_ready_contours.xml\")\n",
    "    st.download_button(\"Download file\", Path(f\"./{datetime}_LMD_ready_contours.xml\").read_text(), f\"./{datetime}_LMD_ready_contours.xml\")\n",
    "    \n",
    "    #create and export dataframe with sample placement in 384 well plate\n",
    "    rows_A_P= [i for i in string.ascii_uppercase[:16]]\n",
    "    columns_1_24 = [str(i) for i in range(1,25)]\n",
    "    df_wp384 = pd.DataFrame('',columns=columns_1_24, index=rows_A_P)\n",
    "    #fill in the dataframe with samples and wells\n",
    "    for i in samples_and_wells:\n",
    "        location = samples_and_wells[i]\n",
    "        df_wp384.at[location[0],location[1:]] = i\n",
    "\n",
    "    if st.button('Download 384 well plate layout'):\n",
    "        df_wp384.to_csv(f\"./{datetime}_384_wellplate.csv\", index=True)\n",
    "        st.write('Your 384 well plate layout has been downloaded')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
